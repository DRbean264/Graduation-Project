{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import autoreload\n",
    "from Frames_Alignment import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dlib_Stability_Check(file,batch_size,cmap,resize,min_size):\n",
    "    landmarks_height = []\n",
    "    \n",
    "    # 帧生成器\n",
    "    frames_gen = yield_frames_through_idx(file,batch_size,min_size,resize)\n",
    "    \n",
    "    while True:\n",
    "        frames = next(frames_gen)\n",
    "        if len(frames) == 0:\n",
    "            break\n",
    "        \n",
    "        #  获取帧中的人脸位置及关键点坐标\n",
    "        batch_of_face_locations,batch_of_landmarks,valid = get_location_landmark(frames,0)\n",
    "        \n",
    "        if not valid:\n",
    "            continue\n",
    "        \n",
    "        #  获取脸颊关键点，眼睛关键点的个数\n",
    "        num_chin = len(batch_of_landmarks[0][0]['chin'])\n",
    "        num_eye = len(batch_of_landmarks[0][0]['left_eye'])\n",
    "        \n",
    "        for landmarks in batch_of_landmarks:\n",
    "            if len(landmarks) != 1:\n",
    "                continue\n",
    "            left_eye_center_y = np.mean([y for x,y in landmarks[0]['left_eyebrow']])\n",
    "            right_eye_center_y = np.mean([y for x,y in landmarks[0]['right_eyebrow']])\n",
    "            eye_center_y = np.mean([left_eye_center_y,right_eye_center_y])\n",
    "            bottom_chin_y = np.max([y for x,y in landmarks[0]['chin']])\n",
    "            \n",
    "            landmarks_height.append(bottom_chin_y - eye_center_y)\n",
    "        \n",
    "        #  如果frames长度不足batch_size，说明视频读完了\n",
    "        if len(frames) != batch_size:\n",
    "            break\n",
    "        \n",
    "    return landmarks_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面有两个数据集VIPL-HR以及BEAN-HR的处理过程  \n",
    "## 只需要选择运行一种数据集下的所有代码就行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIPL-HR数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "cmap = 'RGB'\n",
    "resize = False\n",
    "remove_skin = True\n",
    "min_size = None\n",
    "save_root_path = './Plot-Analysis/Dlib-Stability-Check'\n",
    "dataset_source = \"VIPL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意下面的 **root_dir** 修改成自己电脑上存放VIPL-HR数据集的根目录路径  \n",
    "### 数据集的申请参考[中科院官网](https://vipl.ict.ac.cn/view_database.php?id=15)\n",
    "### 下载后的文件结构都是一致的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"D:\\BaiduNetdiskDownload\\VIPL-HR\\data\"\n",
    "\n",
    "\"\"\"测试者分组的路径\"\"\"\n",
    "people_grouped_path = [os.path.join(root_dir,name) for name in os.listdir(root_dir) if 'zip' not in name]\n",
    "num_grouped = len(people_grouped_path)\n",
    "\n",
    "\"\"\"单个测试者的路径\"\"\"\n",
    "person_path = []\n",
    "for group in people_grouped_path:\n",
    "    person_path.extend([os.path.join(group,name) for name in os.listdir(group)])\n",
    "num_person = len(person_path)\n",
    "\n",
    "\"\"\"所有场景的路径；不寻常数量，即数目不为9个场景的测试者路径；以及所有可能的场景数目\"\"\"\n",
    "scenario_path = []\n",
    "abnormal_number_of_scenarios = []\n",
    "possible_number_of_scenarios = set()\n",
    "for person in person_path:\n",
    "    scenario_path.extend([os.path.join(person,name) for name in os.listdir(person)])\n",
    "    \n",
    "    possible_number_of_scenarios.add(len(os.listdir(person)))\n",
    "    if len(os.listdir(person)) != 9:\n",
    "        abnormal_number_of_scenarios.append(person)\n",
    "\n",
    "\"\"\"检查是否所有场景都有source2，结论：都有\"\"\"\n",
    "for scenario in scenario_path:\n",
    "    if 'source2' not in os.listdir(scenario):\n",
    "        print(scenario)\n",
    "\n",
    "def get_video_path_with_scene_source(scenario_path,scenario='v1',source='source2'):\n",
    "    \"\"\"\n",
    "      获取特定场景和视频源的视频路径\n",
    "    \"\"\"\n",
    "    target_scenario_path = [path for path in scenario_path if os.path.basename(path) == scenario]\n",
    "    \n",
    "    video_path = []\n",
    "    for path in target_scenario_path:\n",
    "        video_path.append(os.path.join(os.path.join(path,source),\"video.avi\"))\n",
    "    \n",
    "    return video_path\n",
    "\n",
    "video_path_v1 = get_video_path_with_scene_source(scenario_path,scenario='v1',source='source2')  #  stable\n",
    "video_path_v3 = get_video_path_with_scene_source(scenario_path,scenario='v3',source='source2')  #  stable and talking\n",
    "video_path_v4 = get_video_path_with_scene_source(scenario_path,scenario='v4',source='source2')  #  stable and bit dark\n",
    "video_path_v5 = get_video_path_with_scene_source(scenario_path,scenario='v5',source='source2')  #  stable and bit light\n",
    "video_path_v6 = get_video_path_with_scene_source(scenario_path,scenario='v6',source='source2')  #  stable and long distance\n",
    "video_path_v7 = get_video_path_with_scene_source(scenario_path,scenario='v7',source='source2')  #  stable after exercise\n",
    "video_path_v8 = get_video_path_with_scene_source(scenario_path,scenario='v8',source='source2')  #  stable after exercise\n",
    "\n",
    "all_video_path_VIPL = video_path_v1 + video_path_v3 + video_path_v4 + video_path_v5 + video_path_v6 + video_path_v7 + video_path_v8\n",
    "# person_id_without_glasses = [12,14,18,19,23,26,28,34,38,39,40,41,48,52,57,58,63,65,67,70,71,74,79,84,85,91,92,95,97,99]\n",
    "\n",
    "# all_video_path_without_glasses = [video for video in all_video_path_VIPL if int(video.split(\"\\\\\")[-4][1:]) in person_id_without_glasses]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEAN-HR数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意下面的 **video_root_path** 是我自己电脑上存放BEAN-HR数据集的根目录路径  \n",
    "### 数据集的暂时不对外开放  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_root_path = 'D:\\\\BaiduNetdiskDownload\\\\ECNU-Dataset-AVC1'\n",
    "batch_size = 10\n",
    "cmap = 'RGB'\n",
    "resize = False\n",
    "remove_skin = True\n",
    "min_size = 1000\n",
    "save_root_path = './Plot-Analysis/Dlib-Stability-Check'\n",
    "dataset_source = \"BEAN\"\n",
    "\n",
    "all_video_path_BEAN = []\n",
    "for dirpath,_,filenames in os.walk(video_root_path):\n",
    "    for file in filenames:\n",
    "        all_video_path_BEAN.append(os.path.join(dirpath,file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用切割框的高的标准差衡量稳定性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = []\n",
    "for idx,video in enumerate(all_video_path_BEAN):\n",
    "    print(\"The {}th video:\".format(idx + 1))\n",
    "    landmarks_height = Dlib_Stability_Check(video,batch_size,cmap,resize,min_size)\n",
    "    print(\"The standard deviation of height is:\",np.std(landmarks_height))\n",
    "    stds.append(np.std(landmarks_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_root_path):\n",
    "    os.makedirs(save_root_path)\n",
    "with open(os.path.join(save_root_path,\"{}-HR.txt\".format(dataset_source)),'w') as f:\n",
    "    f.write(\" \".join([str(std) for std in stds]))\n",
    "\n",
    "plt.hist(stds, bins=61, facecolor=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.xlabel(\"Standard deviation\",fontsize=20)\n",
    "plt.ylabel(\"Frequency\",fontsize=20)\n",
    "plt.xticks(np.arange(0,61,5),np.arange(0,61,5))\n",
    "plt.tick_params(labelsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_root_path,\"{}-HR.png\".format(dataset_source)),dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face_detection] *",
   "language": "python",
   "name": "conda-env-face_detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
